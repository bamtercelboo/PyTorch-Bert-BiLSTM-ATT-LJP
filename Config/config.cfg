[Embed]
pretrained_embed = False
zeros = False
avg = False
uniform = False
nnembed = True
pretrained_embed_file = ./cail_skipgram_w2c/skipgram.200d

[Data]
train_file = ./Data/cail_0530_short/data_train.json
dev_file = ./Data/cail_0530_short/data_valid.json
test_file = ./Data/cail_0530_short/data_test.json
max_count = -1
min_freq = 5
max_train_len = 4000
shuffle = True
epochs_shuffle = True

[Bert]
use_bert = False
bert_dim = 300
bert_train_file = ./Data/Bert/data_train_bert_dim300_100.json
bert_dev_file = ./Data/Bert/data_dev_bert_dim300_100.json
bert_test_file = ./Data/Bert/data_test_bert_dim300_100.json

[BertModel]
use_bert_model = True
bert_model_path = ./Data/bert-base-chinese
bert_model_vocab = bert-base-chinese-vocab.txt
bert_max_char_length = 300
bert_model_max_seq_length = 302
bert_model_batch_size = 2
extract_dim = 3
layers = -1,-2,-3,-4
local_rank = -1
no_cuda = False
do_lower_case = False

[Save]
save_pkl = False
pkl_directory = ./Save_pkl
pkl_data = pkl_data.pkl
pkl_alphabet = pkl_alphabet.pkl
pkl_iter = pkl_iter.pkl
pkl_embed = pkl_embed.pkl
save_dict = True
dict_directory = ./Save_dictionary
word_dict = dictionary_word.txt
label_dict = dictionary_label
save_direction = ./Save_model
save_best_model_dir = ./Save_BModel
save_model = True
save_all_model = False
save_best_model = True
model_name = charge_model
rm_model = True

[Model]
model_bilstm = False
lstm_layers = 1
embed_dim = 200
embed_finetune = True
lstm_hiddens = 200
dropout_emb = 0.5
dropout = 0.5
conv_filter_sizes = 3,4,5
conv_filter_nums = 100
windows_size = 5

[Optimizer]
adam = True
sgd = False
learning_rate = 0.001
weight_decay = 1e-8
clip_max_norm_use = True
clip_max_norm = 10
use_lr_decay = False
lr_rate_decay = 0.75
min_lrate = 0.00005
max_patience = 2

[Train]
num_threads = 1
epochs = 1000
early_max_patience = 1000
backward_batch_size = 1
batch_size = 16
dev_batch_size = 16
test_batch_size = 16
log_interval = 1000

